= About RHCOS

Red Hat Enterprise Linux CoreOS (RHCOS) represents the next generation of single-purpose
container operating system technology. Created by the same development teams
that created Red Hat Enterprise Linux Atomic Host and CoreOS Container Linux,
RHCOS combines the quality standards of Red Hat Enterprise Linux (RHEL)
with the automated, remote upgrade features from Container Linux.

== How Containers are Secured on Red Hat Enterprise Linux CoreOS

Containers enable you to simplify multi-tenancy deployments by deploying
multiple applications on a single host, using the kernel and the container runtime
to spin up each container.

You must have an operating system (OS) that can secure the host kernel and
secure containers from each other. In Linux, containers are just a special type
of process, so securing containers is the same as securing any running process.
Containers should run as a *non-root user*. *Dropping the privilege level or
creating containers with the least amount of privileges possible is recommended*.

Because OpenShift runs on RHCOS and RHEL, the following concepts apply by default to any deployed
cluster and are at the core of what make containers secure on the platform.

- _Linux namespaces_ enable creating an abstraction of a particular global system
resource to make it appear as a separate instance to processes within a
namespace. Consequently, several containers can use the same resource
simultaneously without creating a conflict.

- _SELinux_ provides an additional layer of security to keep containers isolated
from each other and from the host. SELinux allows administrators to enforce
mandatory access controls (MAC) for every user, application, process, and file.

- _CGroups_ (control groups) limit, account for, and isolate the resource usage
(CPU, memory, disk I/O, network, etc.) of a collection of processes. CGroups are
used to ensure that containers on the same host are not impacted by each other.

- _Secure computing mode (seccomp)_ profiles can be associated with a container to
restrict available system calls.

- Deploying containers using _RHCOS_ reduces the attack surface by minimizing the host environment and tuning it for containers.

image::_images/rhcos_layers.png[]

== Key RHCOS features

The following list describes key features of the RHCOS operating system:

* **Based on RHEL**: The underlying operating system consists primarily of RHEL components.
The same quality, security, and control measures that support RHEL also support
RHCOS. For example, RHCOS software is in
RPM packages, and each RHCOS system starts up with a RHEL kernel and a set
of services that are managed by the systemd init system.

* **Controlled immutability**: Although it contains RHEL components, RHCOS
is designed to be managed
more tightly than a default RHEL installation. Management is
performed remotely from the OpenShift Container Platform cluster. When you set up your
RHCOS machines, you can modify only a few system settings. This controlled
immutability allows OpenShift Container Platform to
store the latest state of RHCOS systems in the cluster so it is always
able to create additional machines and perform updates based on the latest RHCOS
configurations.

* **CRI-O container runtime**: Although RHCOS contains features for running the
OCI and libcontainer-formatted containers that Docker requires, it incorporates
the CRI-O container engine instead of the Docker container engine. 
By focusing on features needed by Kubernetes platforms, such as OpenShift Container Platform, 
CRI-O can offer specific compatibility with different Kubernetes versions. CRI-O also offers a smaller
footprint and reduced attack surface than is possible with container engines
that offer a larger feature set. At the moment, CRI-O is only available as a
container engine within OpenShift Container Platform clusters.

* **Set of container tools**: For tasks such as building, copying, and otherwise
managing containers, RHCOS replaces the Docker CLI tool with a compatible
set of container tools. The podman CLI tool supports many container runtime
features, such as running, starting, stopping, listing, and removing containers
and container images. The skopeo CLI tool can copy, authenticate, and sign
images. You can use the crictl CLI tool to work with containers and pods from the
CRI-O container engine. While direct use of these tools in RHCOS is
discouraged, you can use them for debugging purposes.

* **rpm-ostree upgrades**: RHCOS features transactional upgrades using
the `rpm-ostree` system.
Updates are delivered by means of container images and are part of the
OpenShift Container Platform update process. When deployed, the container image is pulled,
extracted, and written to disk, then the bootloader is modified to boot into
the new version. The machine will reboot into the update in a rolling manner to
ensure cluster capacity is minimally impacted.

* **Updated through MachineConfigOperator**:
In OpenShift Container Platform, the Machine Config Operator handles operating system upgrades.
Instead of upgrading individual packages, as is done with `yum`
upgrades, `rpm-ostree` delivers upgrades of the OS as an atomic unit. The
new OS deployment is staged during upgrades and goes into effect on the next reboot.
If something goes wrong with the upgrade, a single rollback and reboot returns the
system to the previous state. RHCOS upgrades in OpenShift Container Platform are performed
during cluster updates.

For RHCOS systems, the layout of the `rpm-ostree` file system has the
 following characteristics:

* `/usr` is where the operating system binaries and libraries are stored and is
 read-only. We do not support altering this.
* `/etc`, `/boot`, `/var` are writable on the system but only intended to be altered
 by the Machine Config Operator.
* `/var/lib/containers` is the graph storage location for storing container
 images.

== Choosing how to configure RHCOS

RHCOS is designed to deploy on an OpenShift Container Platform cluster with a minimal amount
of user configuration. In its most basic form, this consists of:

Because RHCOS systems in OpenShift Container Platform are designed to be fully managed
from the OpenShift Container Platform cluster after that, directly changing an RHCOS machine is
discouraged. Although limited direct access to RHCOS machines
cluster can be accomplished for debugging purposes, *you should not directly configure
RHCOS systems*.
Instead, if you need to add or change features on your OpenShift Container Platform nodes,
consider making changes in the following ways:

* **Kubernetes workload objects (DaemonSets, Deployments, etc.)**: If you need to
add services or other user-level features to your cluster, consider adding them as
Kubernetes workload objects. Keeping those features outside of specific node
configurations is the best way to reduce the risk of breaking the cluster on
subsequent upgrades.

* **Day-2 customizations**: If possible, bring up a cluster without making any
customizations to cluster nodes and make necessary node changes after the cluster is up.
Those changes are easier to track later and less likely to break updates.
Creating MachineConfigs or modifying Operator custom resources
are ways of making these customizations.

* **Day-1 customizations**: For customizations that you must implement when the
cluster first comes up, there are ways of modifying your cluster so changes are
implemented on first boot.
Day-1 customizations can be done through Ignition configs and manifest files
during `openshift-install` or by adding boot options during ISO installs
provisioned by the user.

Here are examples of customizations you could do on day-1:

* **Kernel arguments**: If particular kernel features or tuning is needed on nodes when the cluster first boots.

* **Disk encryption**: If your security needs require that the root filesystem on the nodes are encrypted, such as with FIPS support.

* **Kernel modules**: If a particular hardware device, such as a network card or video card, does not have a usable module available by default in the Linux kernel.

* **Chronyd**: If you want to provide specific clock settings to your nodes,
such as the location of time servers.

To accomplish these tasks, you can augment the `openshift-install` process to include additional
objects such as MachineConfigs.
Those procedures that result in creating MachineConfigs can be passed to the Machine Config Operator
after the cluster is up.